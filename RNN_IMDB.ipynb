{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.datasets import imdb\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data and maximum length of a sequence\n",
    "max_features = 20000\n",
    "maxlen = 30\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielcoelho/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/datasets/imdb.py:101: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/Users/danielcoelho/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/datasets/imdb.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "## Load in the data.  The function automatically tokenizes the text into distinct integers\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = max_features)\n",
    "print(len(x_train), 'train sequences')\n",
    "print(len(x_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 30)\n",
      "x_test shape: (25000, 30)\n"
     ]
    }
   ],
   "source": [
    "# This pads (or truncates) the sequences so that they are of the maximum length\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = maxlen)\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('x_test shape:', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  219,   141,    35,   221,   956,    54,    13,    16,    11,\n",
       "        2714,    61,   322,   423,    12,    38,    76,    59,  1803,\n",
       "          72,     8, 10508,    23,     5,   967,    12,    38,    85,\n",
       "          62,   358,    99], dtype=int32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #Here's what an example sequence looks like\n",
    "x_train[123,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras layers for (Vanilla) RNNs\n",
    "\n",
    "In this exercise, we will not use pre-trained word vectors.  Rather we will learn an embedding as part of the Neural Network.  This is represented by the Embedding Layer below.\n",
    "\n",
    "### Embedding Layer\n",
    "`keras.layers.embeddings.Embedding(input_dim, output_dim, embeddings_initializer='uniform', embeddings_regularizer=None, activity_regularizer=None, embeddings_constraint=None, mask_zero=False, input_length=None)`\n",
    "\n",
    "- This layer maps each integer into a distinct (dense) word vector of length `output_dim`.\n",
    "- Can think of this as learning a word vector embedding \"on the fly\" rather than using an existing mapping (like GloVe)\n",
    "- The `input_dim` should be the size of the vocabulary.\n",
    "- The `input_length` specifies the length of the sequences that the network expects.\n",
    "\n",
    "### SimpleRNN Layer\n",
    "`keras.layers.recurrent.SimpleRNN(units, activation='tanh', use_bias=True, kernel_initializer='glorot_uniform', recurrent_initializer='orthogonal', bias_initializer='zeros', kernel_regularizer=None, recurrent_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, recurrent_constraint=None, bias_constraint=None, dropout=0.0, recurrent_dropout=0.0)`\n",
    "\n",
    "- This is the basic RNN, where the output is also fed back as the \"hidden state\" to the next iteration.\n",
    "- The parameter `units` gives the dimensionality of the output (and therefore the hidden state).  Note that typically there will be another layer after the RNN mapping the (RNN) output to the network output.  So we should think of this value as the desired dimensionality of the hidden state and not necessarily the desired output of the network.\n",
    "- Recall that there are two sets of weights, one for the \"recurrent\" phase and the other for the \"kernel\" phase.  These can be configured separately in terms of their initialization, regularization, etc.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-08 16:02:29.610973: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-08 16:02:29.611210: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 4. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "## Let's build a RNN\n",
    "rnn_hidden_dim = 5\n",
    "word_embedding_dim = 50\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(Embedding(max_features, word_embedding_dim))\n",
    "model_rnn.add(SimpleRNN(rnn_hidden_dim,\n",
    "                       kernel_initializer = initializers.RandomNormal(stddev = 0.001),\n",
    "                       recurrent_initializer = initializers.Identity(gain = 1.0),\n",
    "                       activation = 'relu',\n",
    "                       input_shape = x_train.shape[1:]))\n",
    "model_rnn.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 50)          1000000   \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 5)                 280       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 1,000,286\n",
      "Trainable params: 1,000,286\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Note that most of the parameters come from the embedding layer\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(lr = 0.0001)\n",
    "\n",
    "model_rnn.compile(loss = 'binary_crossentropy',\n",
    "                 optimizer = rmsprop,\n",
    "                 metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielcoelho/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.6792 - accuracy: 0.5813 - val_loss: 0.6462 - val_accuracy: 0.6756\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.6034 - accuracy: 0.6968 - val_loss: 0.5852 - val_accuracy: 0.6986\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.5372 - accuracy: 0.7365 - val_loss: 0.5428 - val_accuracy: 0.7248\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 29s 1ms/step - loss: 0.4949 - accuracy: 0.7635 - val_loss: 0.5233 - val_accuracy: 0.7360\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 28s 1ms/step - loss: 0.4651 - accuracy: 0.7824 - val_loss: 0.5045 - val_accuracy: 0.7468\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.4413 - accuracy: 0.7952 - val_loss: 0.4901 - val_accuracy: 0.7574\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.4219 - accuracy: 0.8099 - val_loss: 0.4777 - val_accuracy: 0.7661\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.4053 - accuracy: 0.8178 - val_loss: 0.4691 - val_accuracy: 0.7714\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.3921 - accuracy: 0.8248 - val_loss: 0.4601 - val_accuracy: 0.7779\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 27s 1ms/step - loss: 0.3814 - accuracy: 0.8319 - val_loss: 0.4571 - val_accuracy: 0.7816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe93a9f6cd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn.fit(x_train, y_train,\n",
    "             batch_size = batch_size,\n",
    "             epochs = 10,\n",
    "             validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 3s 138us/step\n",
      "Test score: 0.4571345684337616\n",
      "Test accuracy 0.7816399931907654\n"
     ]
    }
   ],
   "source": [
    "score, acc = model_rnn.evaluate(x_test, y_test,\n",
    "                               batch_size = batch_size)\n",
    "print('Test score:', score)\n",
    "print('Test accuracy', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "### Your Turn\n",
    "\n",
    "Now do it yourself:\n",
    "- Prepare the data to use sequences of length 80 rather than length 30.  Did it improve the performance?\n",
    "- Try different values of the \"max_features\".  Can you improve the performance?\n",
    "- Try smaller and larger sizes of the RNN hidden dimension.  How does it affect the model performance?  How does it affect the run time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielcoelho/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/datasets/imdb.py:101: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/Users/danielcoelho/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/datasets/imdb.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = max_features)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Out of curiosity, run for 10 more epochs\n",
    "rnn_hidden_dim = 5\n",
    "word_embedding_dim = 50\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(Embedding(max_features, word_embedding_dim))\n",
    "model_rnn.add(SimpleRNN(rnn_hidden_dim,\n",
    "                       kernel_initializer = initializers.RandomNormal(stddev = 0.001),\n",
    "                       recurrent_initializer = initializers.Identity(gain = 1.0),\n",
    "                       activation = 'relu',\n",
    "                       input_shape = x_train.shape[1:]))\n",
    "model_rnn.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(lr = 0.0001)\n",
    "\n",
    "model_rnn.compile(loss = 'binary_crossentropy',\n",
    "                 optimizer = rmsprop,\n",
    "                 metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielcoelho/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 50s 2ms/step - loss: 0.6027 - accuracy: 0.6715 - val_loss: 0.5292 - val_accuracy: 0.7312\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 48s 2ms/step - loss: 0.4601 - accuracy: 0.7841 - val_loss: 0.4666 - val_accuracy: 0.7767\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 48s 2ms/step - loss: 0.3944 - accuracy: 0.8249 - val_loss: 0.4483 - val_accuracy: 0.7820\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 49s 2ms/step - loss: 0.3495 - accuracy: 0.8495 - val_loss: 0.4019 - val_accuracy: 0.8149\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 49s 2ms/step - loss: 0.3192 - accuracy: 0.8644 - val_loss: 0.3846 - val_accuracy: 0.8276\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 49s 2ms/step - loss: 0.2991 - accuracy: 0.8736 - val_loss: 0.3773 - val_accuracy: 0.8318\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 49s 2ms/step - loss: 0.2833 - accuracy: 0.8830 - val_loss: 0.3704 - val_accuracy: 0.8346\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 52s 2ms/step - loss: 0.2713 - accuracy: 0.8872 - val_loss: 0.3769 - val_accuracy: 0.8328\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 49s 2ms/step - loss: 0.2611 - accuracy: 0.8916 - val_loss: 0.3891 - val_accuracy: 0.8281\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 52s 2ms/step - loss: 0.2524 - accuracy: 0.8959 - val_loss: 0.3866 - val_accuracy: 0.8330\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe8a0557a90>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn.fit(x_train, y_train,\n",
    "             batch_size = batch_size,\n",
    "             epochs = 10,\n",
    "             validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielcoelho/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/datasets/imdb.py:101: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/Users/danielcoelho/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/keras/datasets/imdb.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "max_features = 500\n",
    "maxlen = 80\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = max_features)\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen = maxlen)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_hidden_dim = 5\n",
    "word_embedding_dim = 50\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(Embedding(max_features, word_embedding_dim))\n",
    "model_rnn.add(SimpleRNN(rnn_hidden_dim,\n",
    "                       kernel_initializer = initializers.RandomNormal(stddev = 0.001),\n",
    "                       recurrent_initializer = initializers.Identity(gain = 1.0),\n",
    "                       activation = 'relu',\n",
    "                       input_shape = x_train.shape[1:]))\n",
    "model_rnn.add(Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(lr = 0.0001)\n",
    "\n",
    "model_rnn.compile(loss = 'binary_crossentropy',\n",
    "                 optimizer = rmsprop,\n",
    "                 metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danielcoelho/opt/anaconda3/envs/tensorflow/lib/python3.7/site-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 39s 2ms/step - loss: 0.6416 - accuracy: 0.6216 - val_loss: 0.5732 - val_accuracy: 0.7015\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.5475 - accuracy: 0.7214 - val_loss: 0.5513 - val_accuracy: 0.7186\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.5150 - accuracy: 0.7432 - val_loss: 0.5087 - val_accuracy: 0.7458\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.4933 - accuracy: 0.7590 - val_loss: 0.4877 - val_accuracy: 0.7581\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.4768 - accuracy: 0.7715 - val_loss: 0.4793 - val_accuracy: 0.7669\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.4655 - accuracy: 0.7793 - val_loss: 0.4650 - val_accuracy: 0.7757\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.4582 - accuracy: 0.7821 - val_loss: 0.4576 - val_accuracy: 0.7800\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.4525 - accuracy: 0.7861 - val_loss: 0.4537 - val_accuracy: 0.7817\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.4479 - accuracy: 0.7876 - val_loss: 0.4537 - val_accuracy: 0.7830\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.4455 - accuracy: 0.7897 - val_loss: 0.4480 - val_accuracy: 0.7874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe700582a10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn.fit(x_train, y_train,\n",
    "             batch_size = batch_size,\n",
    "             epochs = 10,\n",
    "             validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/10\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.4433 - accuracy: 0.7897 - val_loss: 0.4486 - val_accuracy: 0.7870\n",
      "Epoch 2/10\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.4417 - accuracy: 0.7913 - val_loss: 0.4460 - val_accuracy: 0.7888\n",
      "Epoch 3/10\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.4403 - accuracy: 0.7926 - val_loss: 0.4444 - val_accuracy: 0.7907\n",
      "Epoch 4/10\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.4390 - accuracy: 0.7937 - val_loss: 0.4438 - val_accuracy: 0.7908\n",
      "Epoch 5/10\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.4381 - accuracy: 0.7950 - val_loss: 0.4636 - val_accuracy: 0.7780\n",
      "Epoch 6/10\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.4371 - accuracy: 0.7944 - val_loss: 0.4462 - val_accuracy: 0.7894\n",
      "Epoch 7/10\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.4361 - accuracy: 0.7951 - val_loss: 0.4429 - val_accuracy: 0.7920\n",
      "Epoch 8/10\n",
      "25000/25000 [==============================] - 37s 1ms/step - loss: 0.4351 - accuracy: 0.7952 - val_loss: 0.4427 - val_accuracy: 0.7912\n",
      "Epoch 9/10\n",
      "25000/25000 [==============================] - 38s 2ms/step - loss: 0.4337 - accuracy: 0.7973 - val_loss: 0.4428 - val_accuracy: 0.7918\n",
      "Epoch 10/10\n",
      "25000/25000 [==============================] - 43s 2ms/step - loss: 0.4329 - accuracy: 0.7970 - val_loss: 0.4420 - val_accuracy: 0.7922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fe8a85a11d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn.fit(x_train, y_train,\n",
    "             batch_size = batch_size,\n",
    "             epochs = 10,\n",
    "             validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
